{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datatrain = pd.read_csv('train2.csv')\n",
    "datatest = pd.read_csv('test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Models to test\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#evaluate performances\n",
    "from sklearn.metrics import make_scorer, accuracy_score \n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = datatrain.drop(labels=[\"PassengerId\", \"Survived\"], axis=1) #define training features set\n",
    "y_train = datatrain[\"Survived\"] #define training label set\n",
    "X_test = datatest.drop(\"PassengerId\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Simple separation between training and testing\n",
    "X_training, X_valid, y_training, y_valid = train_test_split(X_train, y_train, \n",
    "                                                            test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc_clf = SVC() \n",
    "\n",
    "parameters_svc = {\"kernel\": [\"rbf\", \"linear\"], \"probability\": [True, False], \"verbose\": [True, False]}\n",
    "\n",
    "grid_svc = GridSearchCV(svc_clf, parameters_svc, scoring=make_scorer(accuracy_score))\n",
    "grid_svc.fit(X_training, y_training)\n",
    "\n",
    "svc_clf = grid_svc.best_estimator_\n",
    "\n",
    "svc_clf.fit(X_training, y_training)\n",
    "pred_svc = svc_clf.predict(X_valid)\n",
    "acc_svc = accuracy_score(y_valid, pred_svc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linsvc_clf = LinearSVC()\n",
    "\n",
    "parameters_linsvc = {\"multi_class\": [\"ovr\", \"crammer_singer\"], \"fit_intercept\": [True, False], \"max_iter\": [100, 500, 1000, 1500]}\n",
    "\n",
    "grid_linsvc = GridSearchCV(linsvc_clf, parameters_linsvc, scoring=make_scorer(accuracy_score))\n",
    "grid_linsvc.fit(X_training, y_training)\n",
    "\n",
    "linsvc_clf = grid_linsvc.best_estimator_\n",
    "\n",
    "linsvc_clf.fit(X_training, y_training)\n",
    "pred_linsvc = linsvc_clf.predict(X_valid)\n",
    "acc_linsvc = accuracy_score(y_valid, pred_linsvc)\n",
    "\n",
    "print(\"The Score for LinearSVC is: \" + str(acc_linsvc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "parameters_rf = {\"n_estimators\": [4, 5, 6, 7, 8, 9, 10, 15], \"criterion\": [\"gini\", \"entropy\"], \"max_features\": [\"auto\", \"sqrt\", \"log2\"], \n",
    "                 \"max_depth\": [2, 3, 5, 10], \"min_samples_split\": [2, 3, 5, 10]}\n",
    "\n",
    "grid_rf = GridSearchCV(rf_clf, parameters_rf, scoring=make_scorer(accuracy_score))\n",
    "grid_rf.fit(X_training, y_training)\n",
    "\n",
    "rf_clf = grid_rf.best_estimator_\n",
    "\n",
    "rf_clf.fit(X_training, y_training)\n",
    "pred_rf = rf_clf.predict(X_valid)\n",
    "acc_rf = accuracy_score(y_valid, pred_rf)\n",
    "\n",
    "print(\"The Score for Random Forest is: \" + str(acc_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logistic Regression \n",
    "logreg_clf = LogisticRegression()\n",
    "\n",
    "parameters_logreg = {\"penalty\": [\"l2\"], \"fit_intercept\": [True, False], \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\n",
    "                     \"max_iter\": [50, 100, 200], \"warm_start\": [True, False]}\n",
    "\n",
    "grid_logreg = GridSearchCV(logreg_clf, parameters_logreg, scoring=make_scorer(accuracy_score))\n",
    "grid_logreg.fit(X_training, y_training)\n",
    "\n",
    "logreg_clf = grid_logreg.best_estimator_\n",
    "\n",
    "logreg_clf.fit(X_training, y_training)\n",
    "pred_logreg = logreg_clf.predict(X_valid)\n",
    "acc_logreg = accuracy_score(y_valid, pred_logreg)\n",
    "\n",
    "print(\"The Score for Logistic Regression is: \" + str(acc_logreg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "parameters_knn = {\"n_neighbors\": [3, 5, 10, 15], \"weights\": [\"uniform\", \"distance\"], \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\"],\n",
    "                  \"leaf_size\": [20, 30, 50]}\n",
    "\n",
    "grid_knn = GridSearchCV(knn_clf, parameters_knn, scoring=make_scorer(accuracy_score))\n",
    "grid_knn.fit(X_training, y_training)\n",
    "\n",
    "knn_clf = grid_knn.best_estimator_\n",
    "\n",
    "knn_clf.fit(X_training, y_training)\n",
    "pred_knn = knn_clf.predict(X_valid)\n",
    "acc_knn = accuracy_score(y_valid, pred_knn)\n",
    "\n",
    "print(\"The Score for KNeighbors is: \" + str(acc_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leave One Out Cross Validation\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "X = np.array([[1, 2], [3, 4]])\n",
    "y = np.array([1, 2])\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(X)\n",
    "\n",
    "for train_index, test_index in loo.split(X):\n",
    "        print(\"train:\", train_index, \"validation:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K fold cross validation\n",
    "from sklearn.model_selection import KFold \n",
    "kf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=None) \n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "      print(\"Train:\", train_index, \"Validation:\",test_index)\n",
    "      X_train, X_test = X[train_index], X[test_index] \n",
    "      y_train, y_test = y[train_index], y[test_index]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
